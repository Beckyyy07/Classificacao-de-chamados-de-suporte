{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2c7f0caa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Error loading punkt: <urlopen error [SSL:\n",
      "[nltk_data]     CERTIFICATE_VERIFY_FAILED] certificate verify failed:\n",
      "[nltk_data]     Basic Constraints of CA cert not marked critical\n",
      "[nltk_data]     (_ssl.c:1028)>\n",
      "[nltk_data] Error loading stopwords: <urlopen error [SSL:\n",
      "[nltk_data]     CERTIFICATE_VERIFY_FAILED] certificate verify failed:\n",
      "[nltk_data]     Basic Constraints of CA cert not marked critical\n",
      "[nltk_data]     (_ssl.c:1028)>\n",
      "[nltk_data] Error loading wordnet: <urlopen error [SSL:\n",
      "[nltk_data]     CERTIFICATE_VERIFY_FAILED] certificate verify failed:\n",
      "[nltk_data]     Basic Constraints of CA cert not marked critical\n",
      "[nltk_data]     (_ssl.c:1028)>\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "import string\n",
    "\n",
    "# Baixa os recursos necessários do NLTK\n",
    "nltk.download('punkt')        # Tokenizador pré-treinado\n",
    "nltk.download('stopwords')    # Lista de stopwords (palavras irrelevantes) em vários idiomas\n",
    "nltk.download('wordnet')      # Base de dados semântica usada na lematização (em inglês)\n",
    "\n",
    "# Importa componentes do NLTK\n",
    "from nltk.corpus import stopwords  # Lista de palavras irrelevantes para remoção\n",
    "from nltk.stem import SnowballStemmer, RSLPStemmer, PorterStemmer, WordNetLemmatizer  # Stemmers e lematizador\n",
    "from nltk.tokenize import TweetTokenizer  # Tokenizador ideal para textos informais (como tweets, emojis, hashtags)\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "057a9e61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject</th>\n",
       "      <th>body</th>\n",
       "      <th>answer</th>\n",
       "      <th>type</th>\n",
       "      <th>queue</th>\n",
       "      <th>priority</th>\n",
       "      <th>language</th>\n",
       "      <th>version</th>\n",
       "      <th>tag_1</th>\n",
       "      <th>tag_2</th>\n",
       "      <th>tag_3</th>\n",
       "      <th>tag_4</th>\n",
       "      <th>tag_5</th>\n",
       "      <th>tag_6</th>\n",
       "      <th>tag_7</th>\n",
       "      <th>tag_8</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Wesentlicher Sicherheitsvorfall</td>\n",
       "      <td>Sehr geehrtes Support-Team,\\n\\nich möchte eine...</td>\n",
       "      <td>Vielen Dank für die Meldung des kritischen Sic...</td>\n",
       "      <td>Incident</td>\n",
       "      <td>Technical Support</td>\n",
       "      <td>high</td>\n",
       "      <td>de</td>\n",
       "      <td>51</td>\n",
       "      <td>Security</td>\n",
       "      <td>Outage</td>\n",
       "      <td>Disruption</td>\n",
       "      <td>Data Breach</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Account Disruption</td>\n",
       "      <td>Dear Customer Support Team,\\n\\nI am writing to...</td>\n",
       "      <td>Thank you for reaching out, &lt;name&gt;. We are awa...</td>\n",
       "      <td>Incident</td>\n",
       "      <td>Technical Support</td>\n",
       "      <td>high</td>\n",
       "      <td>en</td>\n",
       "      <td>51</td>\n",
       "      <td>Account</td>\n",
       "      <td>Disruption</td>\n",
       "      <td>Outage</td>\n",
       "      <td>IT</td>\n",
       "      <td>Tech Support</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           subject  \\\n",
       "0  Wesentlicher Sicherheitsvorfall   \n",
       "1               Account Disruption   \n",
       "\n",
       "                                                body  \\\n",
       "0  Sehr geehrtes Support-Team,\\n\\nich möchte eine...   \n",
       "1  Dear Customer Support Team,\\n\\nI am writing to...   \n",
       "\n",
       "                                              answer      type  \\\n",
       "0  Vielen Dank für die Meldung des kritischen Sic...  Incident   \n",
       "1  Thank you for reaching out, <name>. We are awa...  Incident   \n",
       "\n",
       "               queue priority language  version     tag_1       tag_2  \\\n",
       "0  Technical Support     high       de       51  Security      Outage   \n",
       "1  Technical Support     high       en       51   Account  Disruption   \n",
       "\n",
       "        tag_3        tag_4         tag_5 tag_6 tag_7 tag_8  \n",
       "0  Disruption  Data Breach           NaN   NaN   NaN   NaN  \n",
       "1      Outage           IT  Tech Support   NaN   NaN   NaN  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Carregando DF\n",
    "df = pd.read_csv('database/aa_dataset-tickets-multi-lang-5-2-50-version.csv')\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0a172ddc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "subject     object\n",
       "body        object\n",
       "answer      object\n",
       "type        object\n",
       "queue       object\n",
       "priority    object\n",
       "language    object\n",
       "version      int64\n",
       "tag_1       object\n",
       "tag_2       object\n",
       "tag_3       object\n",
       "tag_4       object\n",
       "tag_5       object\n",
       "tag_6       object\n",
       "tag_7       object\n",
       "tag_8       object\n",
       "dtype: object"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d9c98132",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['de' 'en']\n",
      "['Incident' 'Request' 'Problem' 'Change']\n"
     ]
    }
   ],
   "source": [
    "# Verificando idiomas do DF\n",
    "print(df['language'].unique())\n",
    "\n",
    "# Verificando categorias dos chamados\n",
    "print(df['type'].unique())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6eb8901b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtrando os emaisl apenas na lingua inglesa\n",
    "df_en = df[df['language'] == \"en\"]\n",
    "\n",
    "# Removendo colunas não utilizadas\n",
    "df_en = df_en.drop(columns= [\"subject\", \"answer\", \"queue\", \"priority\", \"language\", \"version\", \"tag_1\", \"tag_2\", \"tag_3\", \"tag_4\", \"tag_5\", \"tag_6\", \"tag_7\", \"tag_8\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6cea329a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "body    0\n",
       "type    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Verificando se os dados necessário estão no df\n",
    "df_en.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36ce498d",
   "metadata": {},
   "source": [
    "# Pré-processamento do texto"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7a16001",
   "metadata": {},
   "source": [
    "### Tokenização"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1390da4",
   "metadata": {},
   "source": [
    "Dividir o texto em unidades menores que podem ser facilmente processados ​​por modelos de PNL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f4aa5bd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenizador(data):\n",
    "    # Inicializar a classe tokenizer\n",
    "    tokenizer = TweetTokenizer()\n",
    "    tokenized_text = tokenizer.tokenize(data)\n",
    "    \n",
    "    return tokenized_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "de8024c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_en['tokenized_body'] = df_en['body'].apply(tokenizador)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6d1c1555",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>body</th>\n",
       "      <th>type</th>\n",
       "      <th>tokenized_body</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Dear Customer Support Team,\\n\\nI am writing to...</td>\n",
       "      <td>Incident</td>\n",
       "      <td>[Dear, Customer, Support, Team, ,, \\, n, \\, nI...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Dear Customer Support Team,\\n\\nI hope this mes...</td>\n",
       "      <td>Request</td>\n",
       "      <td>[Dear, Customer, Support, Team, ,, \\, n, \\, nI...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Dear Customer Support Team,\\n\\nI hope this mes...</td>\n",
       "      <td>Request</td>\n",
       "      <td>[Dear, Customer, Support, Team, ,, \\, n, \\, nI...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Dear Support Team,\\n\\nI hope this message reac...</td>\n",
       "      <td>Problem</td>\n",
       "      <td>[Dear, Support, Team, ,, \\, n, \\, nI, hope, th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Dear Customer Support,\\n\\nI hope this message ...</td>\n",
       "      <td>Request</td>\n",
       "      <td>[Dear, Customer, Support, ,, \\, n, \\, nI, hope...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28578</th>\n",
       "      <td>An unexpected billing discrepancy has been not...</td>\n",
       "      <td>Incident</td>\n",
       "      <td>[An, unexpected, billing, discrepancy, has, be...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28580</th>\n",
       "      <td>A data breach has occurred, which might be rel...</td>\n",
       "      <td>Problem</td>\n",
       "      <td>[A, data, breach, has, occurred, ,, which, mig...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28582</th>\n",
       "      <td>The data analytics tool experiences sluggish p...</td>\n",
       "      <td>Incident</td>\n",
       "      <td>[The, data, analytics, tool, experiences, slug...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28585</th>\n",
       "      <td>Requesting an update on the integration featur...</td>\n",
       "      <td>Change</td>\n",
       "      <td>[Requesting, an, update, on, the, integration,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28586</th>\n",
       "      <td>Looking for detailed information on the projec...</td>\n",
       "      <td>Request</td>\n",
       "      <td>[Looking, for, detailed, information, on, the,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16338 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    body      type  \\\n",
       "1      Dear Customer Support Team,\\n\\nI am writing to...  Incident   \n",
       "2      Dear Customer Support Team,\\n\\nI hope this mes...   Request   \n",
       "3      Dear Customer Support Team,\\n\\nI hope this mes...   Request   \n",
       "4      Dear Support Team,\\n\\nI hope this message reac...   Problem   \n",
       "5      Dear Customer Support,\\n\\nI hope this message ...   Request   \n",
       "...                                                  ...       ...   \n",
       "28578  An unexpected billing discrepancy has been not...  Incident   \n",
       "28580  A data breach has occurred, which might be rel...   Problem   \n",
       "28582  The data analytics tool experiences sluggish p...  Incident   \n",
       "28585  Requesting an update on the integration featur...    Change   \n",
       "28586  Looking for detailed information on the projec...   Request   \n",
       "\n",
       "                                          tokenized_body  \n",
       "1      [Dear, Customer, Support, Team, ,, \\, n, \\, nI...  \n",
       "2      [Dear, Customer, Support, Team, ,, \\, n, \\, nI...  \n",
       "3      [Dear, Customer, Support, Team, ,, \\, n, \\, nI...  \n",
       "4      [Dear, Support, Team, ,, \\, n, \\, nI, hope, th...  \n",
       "5      [Dear, Customer, Support, ,, \\, n, \\, nI, hope...  \n",
       "...                                                  ...  \n",
       "28578  [An, unexpected, billing, discrepancy, has, be...  \n",
       "28580  [A, data, breach, has, occurred, ,, which, mig...  \n",
       "28582  [The, data, analytics, tool, experiences, slug...  \n",
       "28585  [Requesting, an, update, on, the, integration,...  \n",
       "28586  [Looking, for, detailed, information, on, the,...  \n",
       "\n",
       "[16338 rows x 3 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_en"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "872f6277",
   "metadata": {},
   "source": [
    "### Remoção de stopwords"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bf87ac4",
   "metadata": {},
   "source": [
    "São consideradas como tendo pouco valor semântico ou são insignificantes para a tarefa"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa7ce3dd",
   "metadata": {},
   "source": [
    "Cada linguagem, tem sua lista de stop words. Como a língua dos textos que estamos pré-processando é inglês, vamos lidar com elas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "254fd7ba",
   "metadata": {},
   "outputs": [
    {
     "ename": "LookupError",
     "evalue": "\n**********************************************************************\n  Resource \u001b[93mstopwords\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('stopwords')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93mcorpora/stopwords\u001b[0m\n\n  Searched in:\n    - 'C:\\\\Users\\\\Rebeka.Dias/nltk_data'\n    - 'c:\\\\workspace\\\\Classificacao-de-chamados-de-suporte\\\\venv\\\\nltk_data'\n    - 'c:\\\\workspace\\\\Classificacao-de-chamados-de-suporte\\\\venv\\\\share\\\\nltk_data'\n    - 'c:\\\\workspace\\\\Classificacao-de-chamados-de-suporte\\\\venv\\\\lib\\\\nltk_data'\n    - 'C:\\\\Users\\\\Rebeka.Dias\\\\AppData\\\\Roaming\\\\nltk_data'\n    - 'C:\\\\nltk_data'\n    - 'D:\\\\nltk_data'\n    - 'E:\\\\nltk_data'\n**********************************************************************\n",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mLookupError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\workspace\\Classificacao-de-chamados-de-suporte\\venv\\Lib\\site-packages\\nltk\\corpus\\util.py:84\u001b[39m, in \u001b[36mLazyCorpusLoader.__load\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     83\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m84\u001b[39m     root = \u001b[43mnltk\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfind\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43mf\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msubdir\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[33;43m/\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mzip_name\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     85\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mLookupError\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\workspace\\Classificacao-de-chamados-de-suporte\\venv\\Lib\\site-packages\\nltk\\data.py:579\u001b[39m, in \u001b[36mfind\u001b[39m\u001b[34m(resource_name, paths)\u001b[39m\n\u001b[32m    578\u001b[39m resource_not_found = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00msep\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mmsg\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00msep\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m579\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mLookupError\u001b[39;00m(resource_not_found)\n",
      "\u001b[31mLookupError\u001b[39m: \n**********************************************************************\n  Resource \u001b[93mstopwords\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('stopwords')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93mcorpora/stopwords.zip/stopwords/\u001b[0m\n\n  Searched in:\n    - 'C:\\\\Users\\\\Rebeka.Dias/nltk_data'\n    - 'c:\\\\workspace\\\\Classificacao-de-chamados-de-suporte\\\\venv\\\\nltk_data'\n    - 'c:\\\\workspace\\\\Classificacao-de-chamados-de-suporte\\\\venv\\\\share\\\\nltk_data'\n    - 'c:\\\\workspace\\\\Classificacao-de-chamados-de-suporte\\\\venv\\\\lib\\\\nltk_data'\n    - 'C:\\\\Users\\\\Rebeka.Dias\\\\AppData\\\\Roaming\\\\nltk_data'\n    - 'C:\\\\nltk_data'\n    - 'D:\\\\nltk_data'\n    - 'E:\\\\nltk_data'\n**********************************************************************\n",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mLookupError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[29]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m stopwords_en = \u001b[38;5;28mset\u001b[39m(\u001b[43mstopwords\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwords\u001b[49m(\u001b[33m'\u001b[39m\u001b[33menglish\u001b[39m\u001b[33m'\u001b[39m))\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\workspace\\Classificacao-de-chamados-de-suporte\\venv\\Lib\\site-packages\\nltk\\corpus\\util.py:120\u001b[39m, in \u001b[36mLazyCorpusLoader.__getattr__\u001b[39m\u001b[34m(self, attr)\u001b[39m\n\u001b[32m    117\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m attr == \u001b[33m\"\u001b[39m\u001b[33m__bases__\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    118\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mLazyCorpusLoader object has no attribute \u001b[39m\u001b[33m'\u001b[39m\u001b[33m__bases__\u001b[39m\u001b[33m'\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m120\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m__load\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    121\u001b[39m \u001b[38;5;66;03m# This looks circular, but its not, since __load() changes our\u001b[39;00m\n\u001b[32m    122\u001b[39m \u001b[38;5;66;03m# __class__ to something new:\u001b[39;00m\n\u001b[32m    123\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, attr)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\workspace\\Classificacao-de-chamados-de-suporte\\venv\\Lib\\site-packages\\nltk\\corpus\\util.py:86\u001b[39m, in \u001b[36mLazyCorpusLoader.__load\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     84\u001b[39m             root = nltk.data.find(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.subdir\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mzip_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     85\u001b[39m         \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mLookupError\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m86\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[32m     88\u001b[39m \u001b[38;5;66;03m# Load the corpus.\u001b[39;00m\n\u001b[32m     89\u001b[39m corpus = \u001b[38;5;28mself\u001b[39m.__reader_cls(root, *\u001b[38;5;28mself\u001b[39m.__args, **\u001b[38;5;28mself\u001b[39m.__kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\workspace\\Classificacao-de-chamados-de-suporte\\venv\\Lib\\site-packages\\nltk\\corpus\\util.py:81\u001b[39m, in \u001b[36mLazyCorpusLoader.__load\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     79\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     80\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m81\u001b[39m         root = \u001b[43mnltk\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfind\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43mf\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msubdir\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[33;43m/\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m__name\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     82\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mLookupError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m     83\u001b[39m         \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\workspace\\Classificacao-de-chamados-de-suporte\\venv\\Lib\\site-packages\\nltk\\data.py:579\u001b[39m, in \u001b[36mfind\u001b[39m\u001b[34m(resource_name, paths)\u001b[39m\n\u001b[32m    577\u001b[39m sep = \u001b[33m\"\u001b[39m\u001b[33m*\u001b[39m\u001b[33m\"\u001b[39m * \u001b[32m70\u001b[39m\n\u001b[32m    578\u001b[39m resource_not_found = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00msep\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mmsg\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00msep\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m579\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mLookupError\u001b[39;00m(resource_not_found)\n",
      "\u001b[31mLookupError\u001b[39m: \n**********************************************************************\n  Resource \u001b[93mstopwords\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('stopwords')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93mcorpora/stopwords\u001b[0m\n\n  Searched in:\n    - 'C:\\\\Users\\\\Rebeka.Dias/nltk_data'\n    - 'c:\\\\workspace\\\\Classificacao-de-chamados-de-suporte\\\\venv\\\\nltk_data'\n    - 'c:\\\\workspace\\\\Classificacao-de-chamados-de-suporte\\\\venv\\\\share\\\\nltk_data'\n    - 'c:\\\\workspace\\\\Classificacao-de-chamados-de-suporte\\\\venv\\\\lib\\\\nltk_data'\n    - 'C:\\\\Users\\\\Rebeka.Dias\\\\AppData\\\\Roaming\\\\nltk_data'\n    - 'C:\\\\nltk_data'\n    - 'D:\\\\nltk_data'\n    - 'E:\\\\nltk_data'\n**********************************************************************\n"
     ]
    }
   ],
   "source": [
    "stopwords_en = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "693a2a3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stopwords():\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
